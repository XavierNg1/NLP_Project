 Any good statistician knows that the only way to approach a useful average or spot a real trend is to gather data from as broad a set as possible. If you can get information from 100 people, that's good; 10,000 is even better. The more items of information you put into your data set, the more likely it is to end up with accurate averages. By using a set of, say, 3 or 5 data, you can produce results that don't accurately reflect the state of affairs.


For instance, if you find two people who have recently been injured by something silly – like a pillow – and use them as your whole data set, you can make an argument that pillows are categorically dangerous to everybody. No matter which averages you choose to show, as long as you don't reveal your sample size of only 2 people, there's no clear way to refute your claim.
 The most accurate data sets are not only large, they're also broad. A geologist surveying the types of minerals in a desert will have a more accurate list if she collects many samples from every part of the desert, rather than collecting 1,000 samples from the same spot. By limiting the scope of your data set, you can significantly influence the results.


Sometimes, this is useful and done on purpose. People who research using demographic data, for example, might want to find out specifically about the types of jobs that men tend to hold, and therefore will only survey men. As long as this is clearly stated in the data, there's nothing shady about it.
Data from small college research projects in particular tends to get misused to equate a controlled data set with a general result. This is because many research projects at the college level don't have the time or resources to use a broad, random sample of average citizens, and rely only on college students instead. Again, this is fine as long as that information is clearly stated, but news organizations looking for sensational headlines have often obscured the details of a small college study to make it seem much more sweeping.
 This technique is especially sly, as it can lie even with a lot of detail provided for the viewer. The trick here is to use data that can't be fairly compared, and treat them as though they're on equal footing. For example, if you have a city of 100,000 that gained 10,000 residents in 10 years, and you compare it to a town of 10 that gained 10 more residents over the past 10 years, the percentages for each gain will seem to show that the small town grew much more rapidly.


This is sometimes used by people who analyze market data to present a misleading picture of sales figures. Let's say you're tracking sales of apples and oranges, but halfway through the study, there aren't any oranges left because there's a shortage. If you continue to compare data for the rest of the study, there'll be a huge spike in apple sales relative to orange sales, even though apples probably didn't suddenly get more popular.

