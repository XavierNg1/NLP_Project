 It's said that the best defense is a good offense, and it's certainly true in this case.


The stronger a community a wiki has supporting it, and the more good content it maintains, the less of an impact a few bad edits will have on the overall quality. Good content and good community also serve to set a good example for less experienced editors.
A strong community that is actively maintaining a good content base will naturally tend to defend a wiki against vandals because people do not wish to see their work undone.
A larger community can provide more thorough review. Put another way, many hands make light work. When cleanup tasks are distributed among many people, the cost to any one person of spending time on those tasks is small.;
, Every change to every article gets recorded here. The best time to catch vandalism is when it is fresh. The job of patrolling is easiest when there are many people doing it.


Wikipedia, especially, has developed a number of tools to help with watching Recent Changes more efficiently, including various bots, vandalism watch utilities, and IRC feeds of Recent Changes.
 Think about it as a reward or incentive system. What incentive do contributors have? Volunteer editors are not paid to write, so their rewards have more to do with reputation, friendship, and praise. If contributors can attract more and better attention by creating good edits than by creating bad ones, the good will tend to outweigh the bad.
 It may seem counterintuitive and even counterproductive to bother to warn somebody who just wrote a bad word in place of a good page. However, many edits that may not seem productive at first glance could be worth more than they appear, and editors who are interested enough to try editing may be interested enough to make valuable contributions, too. Consider such examples as these:


Test edits. Many people try editing to see if it will work or to see how it will work. Editors may accidentally leave behind stray marks or parts of coding. Some destructive edits and even bad words are added just to see if anybody is watching. The best approach in these cases is to offer instruction.
Corrections. While it is true that some IP addresses change numbers, spellings of names, and hyperlinks in an article to intentionally add incorrect information, an IP address may make a change that is correct. Check a reliable reference before reverting and consider adding the reference to support the data.
Stub articles. Some people start articles because they want to create an article, but they can't write it. Some starts even include requests for the rest of the article to be added. Think of these not as litter but as seeds. Improve them if possible, or help the person who added them to write more.
 Typically, this means the abilities to roll back or revert edits, delete articles, block disruptive editors, and protect pages. This also means that they must have some latitude for making judgment calls about when to use their powers, within the guidelines and policies of the wiki.
 It can be very frustrating to watch a vandal make a mess and have no recourse but to try to fix it faster than it is created.
 Checkusers are users that have the power to discover the IP address of an account. This is an important function because some vandals use multiple IP addresses or accounts to bypass blocks. Checkusers can identify "sockpuppet" accounts (multiple account names made by the same person) and block the underlying IP address(es) if necessary.


Checking the IP address of an editor quickly becomes a privacy concern. Checkusers should never reveal the IP address of an account, nor any more than is necessary to halt disruptive behavior.
Not all sockpuppet accounts are bad. Some good faith editors have sockpuppet accounts because they prefer to keep certain types of edits separate or anonymous, or for test accounts or other functions.
Vandal sockpuppet accounts can often be identified by behavior alone and treated as usual. A checkuser can help if it is a persistent problem.
 If somebody is out of line, it's generally best to tell them that their behavior is not acceptable. Give constructive criticism whenever possible.
 Just as when people write on walls, many vandals do what they do for attention. Don't dwell on the activities of vandals. Just undo malicious edits. Often, paying attention, even if it is lecturing the offender or bemoaning the problem, simply makes matters worse.


It's counterintuitive, but sometimes the best thing to do is to wait to revert. If a vandal gets worse and creates alternate accounts to evade blocks, sometimes it works best to pretend nobody is looking. The lack of attention may be a deterrent.
 Blocks should be used primarily to halt disruptive activities. Be very careful of treating them as punishment. Wikis should have a block policy to guide administrators in the appropriate use of blocks.


Block on user name. If a particular account is causing trouble, block that account. Depending on the wiki, there may be tools built in to prevent users from creating a new account.
Block on IP address. Remember that IP addresses move around and that many are shared or public, as is the case in schools, libraries, and some ISPs.
Set a reasonable expiration. This could be as little as a few minutes, while you get somebody's attention and correct their behavior. A day to a week is often long enough for a first-time offender to decide it is not worth waiting around for the block to end. For persistent vandals a longer block may be warranted.
 For example, Wikipedia keeps a list of the pages that are vandalized the most.



Semi-protection means protecting a page against edits from anonymous users.
Full protection means protecting a page against edits from anybody but administrators.
Protection can often be set to expire after a selected amount of time. Protecting a page temporarily can stop an edit war or get somebody's attention long enough to sort things out.
Remember that protecting a page prevents everybody from editing it, not just the problematic users.
Having a few popular pages attract all the attention is not necessarily a bad thing. It can make vandalism and good-faith new editors both easier to monitor. Watching them closely may be the better way to get new editors.
 Link spam (the insertion of URLs into pages in an effort to promote certain sites) is often created using bots from multiple accounts. While these accounts should generally be blocked, the more effective way to put a stop to this sort of vandalism is by prohibiting the links to be posted to the wiki by any account.
 For example, if images are not used in a wiki or are hosted externally, turn off the ability to upload images. Unused features make for extra things to patrol.
 This Wikipedia page tells the following story about giving warnings:



The little boy's mother was off to market. She worried about her boy, who was always up to some mischief. She sternly admonished him, "Be good. Don't get into trouble. Don't eat all the cabbage. Don't spill all the milk. Don't throw stones at the cow. Don't fall down the well." The boy had done all of these things on other market days. Hoping to head off new trouble, she added, "And don't stuff beans up your nose!" This was a new idea for the boy, who promptly tried it out.
 Share information about vandal activities, open proxies, etc. both within and across projects.
 Some wikis restrict the moving of pages to people with a minimum number of edits, for instance, because this function can be used to do a lot of damage quickly from a newly formed sockpuppet account. Most wikis restrict powers such as deleting pages and blocking users to trusted individuals selected based on their reputation and consistent participation in the community.