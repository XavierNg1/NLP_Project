{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fine_tuning_T5_text_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c07052f3659a442595e9469cc0f36c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29d5c72b7acd44f8aa227b2f90b0b693",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b925e0f43454536a8de034f1d5dd74e",
              "IPY_MODEL_2bcf8d9852d74243b8b6bc648c8d9c6d"
            ]
          }
        },
        "29d5c72b7acd44f8aa227b2f90b0b693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b925e0f43454536a8de034f1d5dd74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_adf76df211e14395ba0e5ca2da24fb1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.99MB of 0.99MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_896a0385434e491c9f20c7b1c90f3fd4"
          }
        },
        "2bcf8d9852d74243b8b6bc648c8d9c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8aab1b9e577d4400805949b63399057c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc4f44dd8f3d406ea72a30a344143a9f"
          }
        },
        "adf76df211e14395ba0e5ca2da24fb1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "896a0385434e491c9f20c7b1c90f3fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8aab1b9e577d4400805949b63399057c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc4f44dd8f3d406ea72a30a344143a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37f6b41095eb42aabb763dea1f2dd1bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0dd61a397dd4364a8d4e5e1458f3443",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e062dd70aad4317a0fbe9e3b434dae0",
              "IPY_MODEL_6101c4e321e34c43a8eb5a54a803fc75"
            ]
          }
        },
        "d0dd61a397dd4364a8d4e5e1458f3443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e062dd70aad4317a0fbe9e3b434dae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b176501f8cdf4e51ae750dc07b2184ee",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2055,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2055,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_beda805e865d47fb945ed676bc973888"
          }
        },
        "6101c4e321e34c43a8eb5a54a803fc75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e9f1547ff74f4738b4e4280b4cb171de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.63k/? [00:00&lt;00:00, 31.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c964fe4b88db40e0aa41571f9f5f3095"
          }
        },
        "b176501f8cdf4e51ae750dc07b2184ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "beda805e865d47fb945ed676bc973888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9f1547ff74f4738b4e4280b4cb171de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c964fe4b88db40e0aa41571f9f5f3095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "969335932897426995eeb4e080f654cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aa5b2e13f08c4013ab2459d9140f2523",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_964af8310d6d4a809580ec7d33c3347d",
              "IPY_MODEL_bc224db84ae84a5bb1cad01937d0b591"
            ]
          }
        },
        "aa5b2e13f08c4013ab2459d9140f2523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "964af8310d6d4a809580ec7d33c3347d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c2c50b3e5db4ad49bf086433a109089",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a36945c35cec46688d10f4a1906fdae9"
          }
        },
        "bc224db84ae84a5bb1cad01937d0b591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_64343f9df4b3495c9f95f29797483533",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:00&lt;00:00, 4.24MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff5432c8b03249caaea19161321928d4"
          }
        },
        "2c2c50b3e5db4ad49bf086433a109089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a36945c35cec46688d10f4a1906fdae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64343f9df4b3495c9f95f29797483533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff5432c8b03249caaea19161321928d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c50ccdbf52b4d069ab7b78cfec346f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2eb5171417e4cbbbe4c51a69877780e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0643738d532548e98484c563f275c639",
              "IPY_MODEL_3990eeeee2d545029d3428353e82f37e"
            ]
          }
        },
        "a2eb5171417e4cbbbe4c51a69877780e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0643738d532548e98484c563f275c639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8b3aa27b27f346889b21a45f98ced112",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1389353,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1389353,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c8c743b1bf74389902a950bbb3dcee0"
          }
        },
        "3990eeeee2d545029d3428353e82f37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c208f394eae4b75870aa00a7f5e5d52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 5.25MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f940b13ff004848aa4e9fd284ffba0a"
          }
        },
        "8b3aa27b27f346889b21a45f98ced112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c8c743b1bf74389902a950bbb3dcee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c208f394eae4b75870aa00a7f5e5d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f940b13ff004848aa4e9fd284ffba0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75ee3792d723450f9cf41f3506f6c2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_26b941a2bac848b48bdfc6c66f827314",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f4a61a33cf444c2f9a256c38c18a4c8d",
              "IPY_MODEL_01be8b3cc72c4a939639c54406fe36e5"
            ]
          }
        },
        "26b941a2bac848b48bdfc6c66f827314": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4a61a33cf444c2f9a256c38c18a4c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25dcae3a7cfe47b9a08e68a660a561f4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4d78b9ac7814ab0aa401aae2d77a192"
          }
        },
        "01be8b3cc72c4a939639c54406fe36e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea2398f2e48a4ec5b4ecbfeb5ad33461",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 14.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdef7ebfdb61466eb84d5a73575a2b9d"
          }
        },
        "25dcae3a7cfe47b9a08e68a660a561f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4d78b9ac7814ab0aa401aae2d77a192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea2398f2e48a4ec5b4ecbfeb5ad33461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdef7ebfdb61466eb84d5a73575a2b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b0ffdb168f8492ea80c0e22d15cb2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1af358a3d7cc428e948f26eec1840eb0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20c344561f7c47f2bf0757df32eabc0a",
              "IPY_MODEL_5f4e1b3bb97a48cf8665923a9788644f"
            ]
          }
        },
        "1af358a3d7cc428e948f26eec1840eb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20c344561f7c47f2bf0757df32eabc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a2d764737164642aec4bd5f5f74cfb5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891691430,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891691430,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b0ad380efa6450a8067943044b3657e"
          }
        },
        "5f4e1b3bb97a48cf8665923a9788644f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d1cc0b575c147daae9f9b0bf979e580",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:16&lt;00:00, 53.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f272ce720d64f5db2ff5bc1a3294061"
          }
        },
        "7a2d764737164642aec4bd5f5f74cfb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b0ad380efa6450a8067943044b3657e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d1cc0b575c147daae9f9b0bf979e580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f272ce720d64f5db2ff5bc1a3294061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC4W8XA1Mwy1"
      },
      "source": [
        "# Fine Tuning Transformer for Summary Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LYgVWOWMwzD"
      },
      "source": [
        "\n",
        "### Introduction\n",
        "\n",
        "In this tutorial we will be fine tuning a transformer model for **Summarization Task**. \n",
        "In this task a summary of a given article/document is generated when passed through a network. There are 2 types of summary generation mechanisms:\n",
        "\n",
        "1. ***Extractive Summary:*** the network calculates the most important sentences from the article and gets them together to provide the most meaningful information from the article.\n",
        "2. ***Abstractive Summary***: The network creates new sentences to encapsulate maximum gist of the article and generates that as output. The sentences in the summary may or may not be contained in the article. \n",
        "\n",
        "In this tutorial we will be generating ***Abstractive Summary***. \n",
        "\n",
        "#### Flow of the notebook\n",
        "\n",
        "* As with all the tutorials previously, this notebook also follows a easy to follow steps. Making the process of fine tuning and training a Transformers model a straight forward task.\n",
        "* However, unlike the other notebooks, in the tutorial, most of the sections have been created into functions, and they are called from the `main()` in the end of the notebook. \n",
        "* This is done to leverage the [Weights and Biases Service](https://www.wandb.com/) WandB in short.\n",
        "* It is a experiment tracking, parameter optimization and artifact management service. That can be very easily integrated to any of the Deep learning or Machine learning frameworks. \n",
        "\n",
        "The notebook will be divided into separate sections to provide a organized walk through for the process used. This process can be modified for individual use cases. The sections are:\n",
        "\n",
        "1. [Preparing Environment and Importing Libraries](#section01)\n",
        "2. [Preparing the Dataset for data processing: Class](#section02)\n",
        "3. [Fine Tuning the Model: Function](#section03)\n",
        "4. [Validating the Model Performance: Function](#section04)\n",
        "5. [Main Function](#section05)\n",
        "    * [Initializing WandB](#section501)\n",
        "    * [Importing and Pre-Processing the domain data](#section502)\n",
        "    * [Creation of Dataset and Dataloader](#section503)\n",
        "    * [Neural Network and Optimizer](#section504)\n",
        "    * [Training Model and Logging to WandB](#section505)\n",
        "    * [Validation and generation of Summary](#section506)\n",
        "6. [Examples of the Summary Generated from the model](#section06)\n",
        "\n",
        "\n",
        "#### Technical Details\n",
        "\n",
        "This script leverages on multiple tools designed by other teams. Details of the tools used below. Please ensure that these elements are present in your setup to successfully implement this script.\n",
        "\n",
        "- **Data**:\n",
        "\t- We are using the News Summary dataset available at [Kaggle](https://www.kaggle.com/sunnysai12345/news-summary)\n",
        "\t- This dataset is the collection created from Newspapers published in India, extracting, details that are listed below.  We are referring only to the first csv file from the data dump: `news_summary.csv`\n",
        "\t- There are`4514` rows of data.  Where each row has the following data-point:\n",
        "\t\t- **author** : Author of the article\n",
        "\t\t- **date** : Date the article was published\n",
        "\t\t- **headline**: Headline for the published article\n",
        "\t\t- **read_more** : URL for the article to follow online\n",
        "\t\t- **text**: This is the summary of the article\n",
        "\t\t- **ctext**: This is the complete article\n",
        "\n",
        "\n",
        "- **Language Model Used**: \n",
        "    - This notebook uses one of the most recent and novel transformers model ***T5***. [Research Paper](https://arxiv.org/abs/1910.10683)    \n",
        "    - ***T5*** in many ways is one of its kind transformers architecture that not only gives state of the art results in many NLP tasks, but also has a very radical approach to NLP tasks.\n",
        "    - **Text-2-Text** - According to the graphic taken from the T5 paper. All NLP tasks are converted to a **text-to-text** problem. Tasks such as translation, classification, summarization and question answering, all of them are treated as a text-to-text conversion problem, rather than seen as separate unique problem statements.\n",
        "    - **Unified approach for NLP Deep Learning** - Since the task is reflected purely in the text input and output, you can use the same model, objective, training procedure, and decoding process to ANY task. Above framework can be used for any task - show Q&A, summarization, etc. \n",
        "   - We will be taking inputs from the T5 paper to prepare our dataset prior to fine tuning and training.    \n",
        "   - [Documentation for python](https://huggingface.co/transformers/model_doc/t5.html)\n",
        "\n",
        "![**Each NLP problem as a “text-to-text” problem** - input: text, output: text](https://miro.medium.com/max/4006/1*D0J1gNQf8vrrUpKeyD8wPA.png) \n",
        "\t \n",
        "\n",
        "\n",
        "- Hardware Requirements: \n",
        "\t- Python 3.6 and above\n",
        "\t- Pytorch, Transformers and\n",
        "\t- All the stock Python ML Library\n",
        "\t- GPU enabled setup \n",
        "   \n",
        "\n",
        "- **Script Objective**:\n",
        "\t- The objective of this script is to fine tune ***T5 *** to be able to generate summary, that a close to or better than the actual summary  while ensuring the important information from the article is not lost.\n",
        "\n",
        "---\n",
        "NOTE: \n",
        "We are using the Weights and Biases Tool-set in  this tutorial. The different components will be explained as we go through the article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GCGfkHvMwzH"
      },
      "source": [
        "<a id='section01'></a>\n",
        "### Preparing Environment and Importing Libraries\n",
        "\n",
        "At this step we will be installing the necessary libraries followed by importing the libraries and modules needed to run our script. \n",
        "We will be installing:\n",
        "* transformers\n",
        "* wandb\n",
        "\n",
        "Libraries imported are:\n",
        "* Pandas\n",
        "* Pytorch\n",
        "* Pytorch Utils for Dataset and Dataloader\n",
        "* Transformers\n",
        "* T5 Model and Tokenizer\n",
        "* wandb\n",
        "\n",
        "Followed by that we will preapre the device for CUDA execeution. This configuration is needed if you want to leverage on onboard GPU. First we will check the GPU avaiable to us, using the nvidia command followed by defining our device.\n",
        "\n",
        "Finally, we will be logging into the [wandb](https://www.wandb.com/) serice using the login command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD_vnyLXZQzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15fdc8c2-5375-48e3-a497-9fc89dc8b89d"
      },
      "source": [
        "!pip install transformers -q\n",
        "!pip install wandb -q\n",
        "!pip install sentencepiece==0.1.91\n",
        "\n",
        "# Code for TPU packages install\n",
        "# !curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.1MB 24.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 48.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 46.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1MB 26.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 52.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 60.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.5MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 10.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzM1_ykHaFur"
      },
      "source": [
        "# Importing stock libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvPxXdKJguYB",
        "outputId": "7037b684-5146-43f5-920a-77b7ddc36034"
      },
      "source": [
        "# Checking out the GPU we have access to. This is output is from the google colab version. \n",
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 29 18:08:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLxxwd1scQNv"
      },
      "source": [
        "# # Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# Preparing for TPU usage\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-ePh9dEKXMw",
        "outputId": "ed4b7864-38d4-4e8d-dd5a-3f6221321273"
      },
      "source": [
        "# Login to wandb to log the model run and all the parameters\n",
        "!wandb login"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH3rBY7HMwzU"
      },
      "source": [
        "<a id='section02'></a>\n",
        "### Preparing the Dataset for data processing: Class\n",
        "\n",
        "We will start with creation of Dataset class - This defines how the text is pre-processed before sending it to the neural network. This dataset will be used the the Dataloader method that will feed  the data in batches to the neural network for suitable training and processing. \n",
        "The Dataloader and Dataset will be used inside the `main()`.\n",
        "Dataset and Dataloader are constructs of the PyTorch library for defining and controlling the data pre-processing and its passage to neural network. For further reading into Dataset and Dataloader read the [docs at PyTorch](https://pytorch.org/docs/stable/data.html)\n",
        "\n",
        "#### *CustomDataset* Dataset Class\n",
        "- This class is defined to accept the Dataframe as input and generate tokenized output that is used by the **T5** model for training. \n",
        "- We are using the **T5** tokenizer to tokenize the data in the `text` and `ctext` column of the dataframe. \n",
        "- The tokenizer uses the ` batch_encode_plus` method to perform tokenization and generate the necessary outputs, namely: `source_id`, `source_mask` from the actual text and `target_id` and `target_mask` from the summary text.\n",
        "- To read further into the tokenizer, [refer to this document](https://huggingface.co/transformers/model_doc/t5.html#t5tokenizer)\n",
        "- The *CustomDataset* class is used to create 2 datasets, for training and for validation.\n",
        "- *Training Dataset* is used to fine tune the model: **80% of the original data**\n",
        "- *Validation Dataset* is used to evaluate the performance of the model. The model has not seen this data during training. \n",
        "\n",
        "#### Dataloader: Called inside the `main()`\n",
        "- Dataloader is used to for creating training and validation dataloader that load data to the neural network in a defined manner. This is needed because all the data from the dataset cannot be loaded to the memory at once, hence the amount of data loaded to the memory and then passed to the neural network needs to be controlled.\n",
        "- This control is achieved using the parameters such as `batch_size` and `max_len`.\n",
        "- Training and Validation dataloaders are used in the training and validation part of the flow respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "932p8NhxeNw4"
      },
      "source": [
        "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = summ_len\n",
        "        self.text = self.data.text\n",
        "        self.ctext = self.data.ctext\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ctext = str(self.ctext[index])\n",
        "        ctext = ' '.join(ctext.split())\n",
        "\n",
        "        text = str(self.text[index])\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL8EZ8nJMwzX"
      },
      "source": [
        "<a id='section03'></a>\n",
        "### Fine Tuning the Model: Function\n",
        "\n",
        "Here we define a training function that trains the model on the training dataset created above, specified number of times (EPOCH), An epoch defines how many times the complete data will be passed through the network. \n",
        "\n",
        "This function is called in the `main()`\n",
        "\n",
        "Following events happen in this function to fine tune the neural network:\n",
        "- The epoch, tokenizer, model, device details, testing_ dataloader and optimizer are passed to the `train ()` when its called from the `main()`\n",
        "- The dataloader passes data to the model based on the batch size.\n",
        "- `language_model_labels` are calculated from the `target_ids` also, `source_id` and `attention_mask` are extracted.\n",
        "- The model outputs first element gives the loss for the forward pass. \n",
        "- Loss value is used to optimize the weights of the neurons in the network.\n",
        "- After every 10 steps the loss value is logged in the wandb service. This log is then used to generate graphs for analysis. Such as [these](https://app.wandb.ai/abhimishra-91/transformers_tutorials_summarization?workspace=user-abhimishra-91)\n",
        "- After every 500 steps the loss value is printed in the console."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaPAR7TWmxoM"
      },
      "source": [
        "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
        "# The model is put into train mode and then we wnumerate over the training loader and passed to the defined network \n",
        "\n",
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "    model.train()\n",
        "    for _,data in enumerate(loader, 0):\n",
        "        y = data['target_ids'].to(device, dtype = torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        if _%10 == 0:\n",
        "            wandb.log({\"Training Loss\": loss.item()})\n",
        "\n",
        "        if _%500==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # xm.optimizer_step(optimizer)\n",
        "        # xm.mark_step()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HpWURa2MwzZ"
      },
      "source": [
        "<a id='section04'></a>\n",
        "### Validating the Model Performance: Function\n",
        "\n",
        "During the validation stage we pass the unseen data(Testing Dataset), trained model, tokenizer and device details to the function to perform the validation run. This step generates new summary for dataset that it has not seen during the training session. \n",
        "\n",
        "This function is called in the `main()`\n",
        "\n",
        "This unseen data is the 20% of `news_summary.csv` which was seperated during the Dataset creation stage. \n",
        "During the validation stage the weights of the model are not updated. We use the generate method for generating new text for the summary. \n",
        "\n",
        "It depends on the `Beam-Search coding` method developed for sequence generation for models with LM head. \n",
        "\n",
        "The generated text and originally summary are decoded from tokens to text and returned to the `main()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9TNdHlQ0CLz"
      },
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask, \n",
        "                max_length=150, \n",
        "                num_beams=2,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "            if _%100==0:\n",
        "                print(f'Completed {_}')\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return predictions, actuals"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4T4Bvs4Mwzc"
      },
      "source": [
        "<a id='section05'></a>\n",
        "### Main Function\n",
        "\n",
        "The `main()` as the name suggests is the central location to execute all the functions/flows created above in the notebook. The following steps are executed in the `main()`:\n",
        "\n",
        "\n",
        "<a id='section501'></a>\n",
        "#### Initializing WandB \n",
        "\n",
        "* The `main()` begins with initializing WandB run under a specific project. This command initiates a new run for each execution of this command. \n",
        "\n",
        "* Before we proceed any further i will give a brief overview of the **[WandB Service](https://www.wandb.com/)**\n",
        "\n",
        "* This service has been created to track ML experiments, Optimize the experiments and save artifacts. It is designed to seamlessly integrate with all the Machine Learning and Deep Learning Frameworks. Each script can be organized into *Project* and each execution of the script will be registered as a *run* in the respective project.\n",
        "\n",
        "* The service can be configured to log several default metrics, such a network weights, hardware usage, gradients and weights of the network. \n",
        "\n",
        "* It can also be used to log user defined metrics, such a loss in the `train()`.\n",
        "\n",
        "* This particular tutorial is logged in the project: **[transformers_tutorials_summarization](https://app.wandb.ai/abhimishra-91/transformers_tutorials_summarization?workspace=user-abhimishra-91)**\n",
        "\n",
        "**One of the charts from the project**\n",
        "![](meta/wandb.png)\n",
        "\n",
        "* Visit the project page to see the details of different runs and what information is logged by the service. \n",
        "\n",
        "* Following the initialization of the WandB service we define configuration parameters that will be used across the tutorial such as `batch_size`, `epoch`, `learning_rate` etc.\n",
        "\n",
        "* These parameters are also passed to the WandB config. The config construct with all the parameters can be optimized using the Sweep service from WandB. Currently, that is outof scope of this tutorial. \n",
        "\n",
        "* Next we defining seed values so that the experiment and results can be reproduced.\n",
        "\n",
        "\n",
        "<a id='section502'></a>\n",
        "#### Importing and Pre-Processing the domain data\n",
        "\n",
        "We will be working with the data and preparing it for fine tuning purposes. \n",
        "*Assuming that the `news_summary.csv` is already downloaded in your `data` folder*\n",
        "\n",
        "* The file is imported as a dataframe and give it the headers as per the documentation.\n",
        "* Cleaning the file to remove the unwanted columns.\n",
        "* A new string is added to the main article column `summarize: ` prior to the actual article. This is done because **T5** had similar formatting for the summarization dataset. \n",
        "* The final Dataframe will be something like this:\n",
        "\n",
        "|text|ctext|\n",
        "|--|--|\n",
        "|summary-1|summarize: article 1|\n",
        "|summary-2|summarize: article 2|\n",
        "|summary-3|summarize: article 3|\n",
        "\n",
        "* Top 5 rows of the dataframe are printed on the console.\n",
        "\n",
        "<a id='section503'></a>\n",
        "#### Creation of Dataset and Dataloader\n",
        "\n",
        "* The updated dataframe is divided into 80-20 ratio for test and validation. \n",
        "* Both the data-frames are passed to the `CustomerDataset` class for tokenization of the new articles and their summaries.\n",
        "* The tokenization is done using the length parameters passed to the class.\n",
        "* Train and Validation parameters are defined and passed to the `pytorch Dataloader contstruct` to create `train` and `validation` data loaders.\n",
        "* These dataloaders will be passed to `train()` and `validate()` respectively for training and validation action.\n",
        "* The shape of datasets is printed in the console.\n",
        "\n",
        "\n",
        "<a id='section504'></a>\n",
        "#### Neural Network and Optimizer\n",
        "\n",
        "* In this stage we define the model and optimizer that will be used for training and to update the weights of the network. \n",
        "* We are using the `t5-base` transformer model for our project. You can read about the `T5 model` and its features above. \n",
        "* We use the `T5ForConditionalGeneration.from_pretrained(\"t5-base\")` commad to define our model. The `T5ForConditionalGeneration` adds a Language Model head to our `T5 model`. The Language Model head allows us to generate text based on the training of `T5 model`.\n",
        "* We are using the `Adam` optimizer for our project. This has been a standard for all our tutorials and is something that can be changed updated to see how different optimizer perform with different learning rates. \n",
        "* There is also a scope for doing more with Optimizer such a decay, momentum to dynamically update the Learning rate and other parameters. All those concepts have been kept out of scope for these tutorials. \n",
        "\n",
        "\n",
        "<a id='section505'></a>\n",
        "#### Training Model and Logging to WandB\n",
        "\n",
        "* Now we log all the metrics in WandB project that we have initialized above.\n",
        "* Followed by that we call the `train()` with all the necessary parameters.\n",
        "* Loss at every 500th step is printed on the console.\n",
        "* Loss at every 10th step is logged as Loss in the WandB service.\n",
        "\n",
        "\n",
        "<a id='section506'></a>\n",
        "#### Validation and generation of Summary\n",
        "\n",
        "* After the training is completed, the validation step is initiated.\n",
        "* As defined in the validation function, the model weights are not updated. We use the fine tuned model to generate new summaries based on the article text.\n",
        "* An output is printed on the console giving a count of how many steps are complete after every 100th step. \n",
        "* The original summary and generated summary are converted into a list and returned to the main function. \n",
        "* Both the lists are used to create the final dataframe with 2 columns **Generated Summary** and **Actual Summary**\n",
        "* The dataframe is saved as a csv file in the local drive.\n",
        "* A qualitative analysis can be done with the Dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn8pbSXLNrn0",
        "outputId": "ee241070-b57c-47e2-8bf3-12472ec63838"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "'''\n",
        "This code is used to create article and summary files from the csv file.\n",
        "The output of the file will be a directory of text files representing seoarate articles and their summaries.\n",
        "Each summary line starts with tag \"@summary\" and the article is followed by \"@article\".\n",
        "'''\n",
        "import re\n",
        "import os\n",
        "\n",
        "\n",
        "# read data from the csv file (from the location it is stored)\n",
        "Data = pd.read_csv(r'/content/drive/MyDrive/wikihowAll.csv')\n",
        "Data = Data.astype(str)\n",
        "rows, columns = Data.shape\n",
        "\n",
        "# create a file to record the file names. This can be later used to divide the dataset in train/dev/test sets\n",
        "title_file = open('titles.txt', 'wb')\n",
        "\n",
        "# The path where the articles are to be saved\n",
        "path = \"articles\"\n",
        "if not os.path.exists(path): os.makedirs(path)\n",
        "\n",
        "# go over the all the articles in the data file\n",
        "for row in range(rows):\n",
        "    abstract = Data.loc[row,'headline']      # headline is the column representing the summary sentences\n",
        "    article = Data.loc[row,'text']           # text is the column representing the article\n",
        "\n",
        "    #  a threshold is used to remove short articles with long summaries as well as articles with no summary\n",
        "    if len(abstract) < (0.75*len(article)):\n",
        "        # remove extra commas in abstracts\n",
        "        abstract = abstract.replace(\".,\",\".\")\n",
        "        abstract = abstract.encode('utf-8')\n",
        "        # remove extra commas in articles\n",
        "        article = re.sub(r'[.]+[\\n]+[,]',\".\\n\", article)\n",
        "        article = article.encode('utf-8')\n",
        "        \n",
        "\n",
        "        # a temporary file is created to initially write the summary, it is later used to separate the sentences of the summary\n",
        "        with open('temporaryFile.txt','wb') as t:\n",
        "            t.write(abstract)\n",
        "        \n",
        "        # file names are created using the alphanumeric charachters from the article titles.\n",
        "        # they are stored in a separate text file.\n",
        "        filename = Data.loc[row,'title']\n",
        "        filename = \"\".join(x for x in filename if x.isalnum())\n",
        "        filename1 = filename + '.txt'\n",
        "        filename = filename.encode('utf-8')\n",
        "        title_file.write(filename+b'\\n')\n",
        "\n",
        "        \n",
        "        with open(path+'/'+filename1,'wb') as f:\n",
        "            # summary sentences will first be written into the file in separate lines\n",
        "            with open('temporaryFile.txt','r') as t:\n",
        "                for line in t:\n",
        "                    line=line.lower()\n",
        "                    if line != \"\\n\" and line != \"\\t\" and line != \" \":\n",
        "                        f.write(b'@summary'+b'\\n')\n",
        "                        f.write(line.encode('utf-8'))\n",
        "                        f.write(b'\\n')\n",
        "                    \n",
        "            # finally the article is written to the file\n",
        "            f.write(b'@article' + b'\\n')    \n",
        "            f.write(article)\n",
        "\n",
        "title_file.close()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y87RSQUIOc67"
      },
      "source": [
        "f = open('titles.txt','r')\n",
        "directory = './articles'\n",
        "n_articles = 0\n",
        "dt_array = []\n",
        "for line in f.readlines():\n",
        "    n_articles+=1\n",
        "    w = open(directory+'/'+line.rstrip()+'.txt','r')\n",
        "    txt = w.read()\n",
        "    w.close()\n",
        "    txt = txt.replace('@summary','')\n",
        "    pair = re.split('@article',txt)\n",
        "    pair = list(map(lambda x : re.sub(r\"\\'s\", \" \\'s\", x),pair))\n",
        "    pair = list(map(lambda x :re.sub(r\"n\\'t\", \" n\\'t\", x),pair))\n",
        "    pair = list(map(lambda x : re.sub(r\"\\s{2,}\", \" \", x), pair))\n",
        "    pair = list(map(lambda x : x.strip(r\"\\n\"),pair))\n",
        "    pair = list(map(lambda x : x.strip(),pair))\n",
        "    pair = list(map(lambda x : x.replace('\\n',''),pair))\n",
        "    dt_array+=[pair]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ1-6t0rPx7u"
      },
      "source": [
        "df_origin = pd.DataFrame(dt_array, columns = ['text','ctext'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "6eP3W3N8P4vi",
        "outputId": "e09d075b-c8d6-4bc5-c6c6-8135cac6ae99"
      },
      "source": [
        "df_origin.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>ctext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>keep related supplies in the same area. make a...</td>\n",
              "      <td>If you're a photographer, keep all the necessa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>create a sketch in the neopoprealist manner of...</td>\n",
              "      <td>See the image for how this drawing develops st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>get a bachelor’s degree. enroll in a studio-ba...</td>\n",
              "      <td>It is possible to become a VFX artist without ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>start with some experience or interest in art....</td>\n",
              "      <td>The best art investors do their research on th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>keep your reference materials, sketches, artic...</td>\n",
              "      <td>As you start planning for a project or work, y...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                              ctext\n",
              "0  keep related supplies in the same area. make a...  If you're a photographer, keep all the necessa...\n",
              "1  create a sketch in the neopoprealist manner of...  See the image for how this drawing develops st...\n",
              "2  get a bachelor’s degree. enroll in a studio-ba...  It is possible to become a VFX artist without ...\n",
              "3  start with some experience or interest in art....  The best art investors do their research on th...\n",
              "4  keep your reference materials, sketches, artic...  As you start planning for a project or work, y..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dnnIVJoP7IE",
        "outputId": "cc9253b3-d5c6-4d78-e275-ebf2056e4a5a"
      },
      "source": [
        "df_origin.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180128, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0X2jJI4P85l"
      },
      "source": [
        "df_test = df_origin.sample(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c07052f3659a442595e9469cc0f36c53",
            "29d5c72b7acd44f8aa227b2f90b0b693",
            "1b925e0f43454536a8de034f1d5dd74e",
            "2bcf8d9852d74243b8b6bc648c8d9c6d",
            "adf76df211e14395ba0e5ca2da24fb1e",
            "896a0385434e491c9f20c7b1c90f3fd4",
            "8aab1b9e577d4400805949b63399057c",
            "fc4f44dd8f3d406ea72a30a344143a9f"
          ]
        },
        "id": "ZtNs9ytpCow2",
        "outputId": "289cf775-93df-4fe6-9b83-693271f70c58"
      },
      "source": [
        "\n",
        "# WandB – Initialize a new run\n",
        "wandb.init(project=\"transformers_tutorials_summarization\")\n",
        "\n",
        "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "# Defining some key variables that will be used later on in the training  \n",
        "config = wandb.config          # Initialize config\n",
        "config.TRAIN_BATCH_SIZE = 2    # input batch size for training (default: 64)\n",
        "config.VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n",
        "config.TRAIN_EPOCHS = 2        # number of epochs to train (default: 10)\n",
        "config.VAL_EPOCHS = 1 \n",
        "config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "config.SEED = 42               # random seed (default: 42)\n",
        "config.MAX_LEN = 512\n",
        "config.SUMMARY_LEN = 150 \n",
        "\n",
        "# Set random seeds and deterministic pytorch for reproducibility\n",
        "torch.manual_seed(config.SEED) # pytorch random seed\n",
        "np.random.seed(config.SEED) # numpy random seed\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# tokenzier for encoding the text\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "\n",
        "# Importing and Pre-Processing the domain data\n",
        "# Selecting the needed columns only. \n",
        "# Adding the summarzie text in front of the text. This is to format the dataset similar to how T5 model was trained for summarization task. \n",
        "#df = pd.read_csv('./data/news_summary.csv',encoding='latin-1')\n",
        "df = df_test\n",
        "df = df[['text','ctext']]\n",
        "df.ctext = 'summarize: ' + df.ctext\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Creation of Dataset and Dataloader\n",
        "# Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n",
        "train_size = 0.8\n",
        "train_dataset=df.sample(frac=train_size,random_state = config.SEED)\n",
        "val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
        "\n",
        "\n",
        "# Creating the Training and Validation dataset for further creation of Dataloader\n",
        "training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "\n",
        "# Defining the parameters for creation of dataloaders\n",
        "train_params = {\n",
        "    'batch_size': config.TRAIN_BATCH_SIZE,\n",
        "    'shuffle': True,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "val_params = {\n",
        "    'batch_size': config.VALID_BATCH_SIZE,\n",
        "    'shuffle': False,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "# Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "\n",
        "\n",
        "# Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "# Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "# Log metrics with wandb\n",
        "wandb.watch(model, log=\"all\")\n",
        "# Training loop\n",
        "print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "for epoch in range(config.TRAIN_EPOCHS):\n",
        "    train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "\n",
        "\n",
        "# Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "# Saving the dataframe as predictions.csv\n",
        "print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
        "for epoch in range(config.VAL_EPOCHS):\n",
        "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "    final_df.to_csv('./predictions.csv')\n",
        "    print('Output Files generated for review')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2h7ubzwz) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 846<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c07052f3659a442595e9469cc0f36c53",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210425_091603-2h7ubzwz/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210425_091603-2h7ubzwz/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Training Loss</td><td>1.49467</td></tr><tr><td>_runtime</td><td>3788</td></tr><tr><td>_timestamp</td><td>1619345954</td></tr><tr><td>_step</td><td>800</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Training Loss</td><td>▅▅▅▃█▆▅▄▃▇▆▅▂▆▃▂▃▅▆▃▅▅▂▇▃▅▄▄▄▂▃▄▅▃▁▅▅▂▃▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">fearless-oath-5</strong>: <a href=\"https://wandb.ai/selgh/transformers_tutorials_summarization/runs/2h7ubzwz\" target=\"_blank\">https://wandb.ai/selgh/transformers_tutorials_summarization/runs/2h7ubzwz</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2h7ubzwz). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">sleek-forest-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/selgh/transformers_tutorials_summarization\" target=\"_blank\">https://wandb.ai/selgh/transformers_tutorials_summarization</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/selgh/transformers_tutorials_summarization/runs/28du7cs5\" target=\"_blank\">https://wandb.ai/selgh/transformers_tutorials_summarization/runs/28du7cs5</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210425_101914-28du7cs5</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "                                                     text                                              ctext\n",
            "91372   open your iphone 's settings. tap general. tap...  summarize: The settings icon looks like gray c...\n",
            "41048   decide what wipe solution you want to use. in ...  summarize: Plain water can be used successfull...\n",
            "134181  use a coupon in store. shop strategically. pay...  summarize: Search for the specific item in the...\n",
            "77082   preheat your oven to 325ºf (162ºc). prepare an...  summarize: Place the oven rack in the lower th...\n",
            "36481   use the terminal velocity formula, v = the squ...  summarize: Plug the following values into that...\n",
            "FULL Dataset: (10000, 2)\n",
            "TRAIN Dataset: (8000, 2)\n",
            "TEST Dataset: (2000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initiating Fine-Tuning for the model on our dataset\n",
            "Epoch: 0, Loss:  9.351834297180176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:760: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  2.211057424545288\n",
            "Epoch: 0, Loss:  3.06658673286438\n",
            "Epoch: 0, Loss:  3.69323992729187\n",
            "Epoch: 0, Loss:  3.283101797103882\n",
            "Epoch: 0, Loss:  2.4946787357330322\n",
            "Epoch: 0, Loss:  2.327772855758667\n",
            "Epoch: 0, Loss:  2.7820825576782227\n",
            "Epoch: 1, Loss:  2.354463577270508\n",
            "Epoch: 1, Loss:  2.1004796028137207\n",
            "Epoch: 1, Loss:  2.261298894882202\n",
            "Epoch: 1, Loss:  2.9001822471618652\n",
            "Epoch: 1, Loss:  2.442944288253784\n",
            "Epoch: 1, Loss:  2.352006673812866\n",
            "Epoch: 1, Loss:  2.2943694591522217\n",
            "Epoch: 1, Loss:  1.8108701705932617\n",
            "Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n",
            "Completed 0\n",
            "Completed 100\n",
            "Completed 200\n",
            "Completed 300\n",
            "Completed 400\n",
            "Completed 500\n",
            "Completed 600\n",
            "Completed 700\n",
            "Completed 800\n",
            "Completed 900\n",
            "Output Files generated for review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbdZEE8-66RF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC9vGwCpvchK"
      },
      "source": [
        "predictions = pd.read_csv('predictions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Rc2B_MPOvgzI",
        "outputId": "57cd1b7c-1aba-4cf2-eefb-7c21780fcbc8"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Generated Text</th>\n",
              "      <th>Actual Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>, mix the ingredients together. pour the mixtu...</td>\n",
              "      <td>decide what wipe solution you want to use. in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>find the following formulas.</td>\n",
              "      <td>use the terminal velocity formula, v = the squ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>you. understand the motivations behind backsta...</td>\n",
              "      <td>try to understand why some people \"backstab\" o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>measure the length of the curtain., add the to...</td>\n",
              "      <td>measure the window.in terms of width, both cur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>apply mascara to your right lashes. coat your ...</td>\n",
              "      <td>apply 1 coat of mascara to your lashes. coat a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1995</td>\n",
              "      <td>cover the rice with water. make a rice cooker.</td>\n",
              "      <td>prepare and rinse the rice as described above....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1996</td>\n",
              "      <td>get ahead on future work. talk to your boss. o...</td>\n",
              "      <td>start on projects or other work scheduled for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1997</td>\n",
              "      <td>and hp wash.</td>\n",
              "      <td>the following describes thieves.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1998</td>\n",
              "      <td>, fill out the form i-94 instructions. complet...</td>\n",
              "      <td>file a form i-129 petition for a nonimmigrant ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>1999</td>\n",
              "      <td>make hotel reservations. bring a small tree. p...</td>\n",
              "      <td>book your trip ahead of time. bring christmas ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                        Actual Text\n",
              "0              0  ...  decide what wipe solution you want to use. in ...\n",
              "1              1  ...  use the terminal velocity formula, v = the squ...\n",
              "2              2  ...  try to understand why some people \"backstab\" o...\n",
              "3              3  ...  measure the window.in terms of width, both cur...\n",
              "4              4  ...  apply 1 coat of mascara to your lashes. coat a...\n",
              "...          ...  ...                                                ...\n",
              "1995        1995  ...  prepare and rinse the rice as described above....\n",
              "1996        1996  ...  start on projects or other work scheduled for ...\n",
              "1997        1997  ...                   the following describes thieves.\n",
              "1998        1998  ...  file a form i-129 petition for a nonimmigrant ...\n",
              "1999        1999  ...  book your trip ahead of time. bring christmas ...\n",
              "\n",
              "[2000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9A0krQ5Uvj4U",
        "outputId": "e0df6230-bab6-4fb2-e332-1f770a557fa6"
      },
      "source": [
        "predictions.iloc[10]['Generated Text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "', boil the water. pour the water into a freezer tray. make ice cubes and spheres.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "DWFt1BR2vr6F",
        "outputId": "d17cd087-23c6-442d-f898-4adcf7c2a05a"
      },
      "source": [
        "predictions.iloc[10]['Actual Text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'use pure water. boil the water twice. pour water into an ice tray or other mold and cover with a plastic wrap to keep out particles. place the ice tray in the freezer. take out the tray and gently remove your clear ice cubes.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0gSkZd81bhu",
        "outputId": "7bd29a81-4427-47b8-fb14-108f516bd4a2"
      },
      "source": [
        "!pip install rouge-score"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.12.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.19.5)\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGMW2wN2v6CA"
      },
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2','rougeL'], use_stemmer=False)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVl3r3_c1-V9",
        "outputId": "fcc5b3c0-05a0-49ec-850c-699bb357ecb7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt') "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "bXaPpnww2B44",
        "outputId": "263ecbb1-6758-4086-ca91-655701ab08b1"
      },
      "source": [
        "!pip install --upgrade nltk"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/37/9532ddd4b1bbb619333d5708aaad9bf1742f051a664c3c6fa6632a105fd8/nltk-3.6.2-py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 29.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 28.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 31.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 31.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 33.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 22.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 23.5MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 21.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 22.2MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 22.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 22.2MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 22.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 22.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 22.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 22.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174kB 22.2MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 22.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194kB 22.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204kB 22.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 235kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 245kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 256kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 266kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 276kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 286kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 296kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 307kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 327kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 337kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 348kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 368kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 378kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 389kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 399kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 419kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 430kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 440kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 460kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 471kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 481kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 491kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 501kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 512kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 522kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 532kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 542kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 552kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 563kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 573kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 583kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 593kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 604kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 614kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 624kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 634kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 645kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 655kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 665kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 675kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 686kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 696kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 706kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 716kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 727kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 737kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 747kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 757kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 768kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 778kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 788kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 798kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 808kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 819kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 829kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 839kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 849kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 860kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 870kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 880kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 890kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 901kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 911kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 921kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 931kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 942kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 952kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 962kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 972kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 983kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 993kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.0MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.0MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1MB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1MB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1MB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1MB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1MB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2MB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.2MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.2MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3MB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3MB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.3MB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3MB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.4MB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.4MB 22.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 22.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.6.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669,
          "referenced_widgets": [
            "37f6b41095eb42aabb763dea1f2dd1bc",
            "d0dd61a397dd4364a8d4e5e1458f3443",
            "5e062dd70aad4317a0fbe9e3b434dae0",
            "6101c4e321e34c43a8eb5a54a803fc75",
            "b176501f8cdf4e51ae750dc07b2184ee",
            "beda805e865d47fb945ed676bc973888",
            "e9f1547ff74f4738b4e4280b4cb171de",
            "c964fe4b88db40e0aa41571f9f5f3095"
          ]
        },
        "id": "BmmW5kGl1aUo",
        "outputId": "ae645575-0355-446a-87d2-244ed041a271"
      },
      "source": [
        "\n",
        "!pip install datasets\n",
        "from datasets import load_metric\n",
        "metric = load_metric(\"meteor\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/4f/8ef6e4df6e92fc02da620ccfac249112619e5c21273a836958160d6e96fb/datasets-1.6.1-py3-none-any.whl (220kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 32.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 32.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 51kB 33.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61kB 35.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 71kB 22.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 81kB 23.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 92kB 21.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 102kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 112kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 122kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 133kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 143kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 153kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 163kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 174kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 184kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 194kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 204kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 215kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 21.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting huggingface-hub<0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 56.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: huggingface-hub, xxhash, fsspec, datasets\n",
            "Successfully installed datasets-1.6.1 fsspec-2021.4.0 huggingface-hub-0.0.8 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37f6b41095eb42aabb763dea1f2dd1bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2055.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zG1qVNa1mJm"
      },
      "source": [
        "mean_rouge1 = 0\n",
        "mean_rougeL = 0\n",
        "mean_rouge2 = 0\n",
        "mean_meteor = 0\n",
        "n_articles = 2000\n",
        "\n",
        "for i in range(predictions.shape[0]) : \n",
        "      predicted_summary  = predictions.iloc[i]['Generated Text']\n",
        "      true_summary = predictions.iloc[i]['Actual Text']\n",
        "      scores = scorer.score(true_summary,\n",
        "                        predicted_summary)\n",
        "      score2 = metric.compute(predictions=[predicted_summary], references=[true_summary])\n",
        "\n",
        "      mean_rouge1 += scores['rouge1'].fmeasure\n",
        "      mean_rougeL += scores['rougeL'].fmeasure\n",
        "      mean_rouge2 += scores['rouge2'].fmeasure\n",
        "      mean_meteor += score2['meteor']\n",
        "\n",
        "mean_rouge1 = mean_rouge1/n_articles\n",
        "mean_rougeL = mean_rougeL/n_articles\n",
        "mean_rouge2 = mean_rouge2/n_articles\n",
        "mean_meteor = mean_meteor/n_articles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JA70qrq6hm_",
        "outputId": "49076ebc-c3fb-4ca7-d191-787169310a28"
      },
      "source": [
        "mean_rouge1,mean_rouge2,mean_rougeL,mean_meteor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3209139913707421,\n",
              " 0.11840571340909892,\n",
              " 0.24991560919848607,\n",
              " 0.18431906192548053)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-7AHWL99I3M"
      },
      "source": [
        "df_test = df_origin.sample(20000)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "969335932897426995eeb4e080f654cb",
            "aa5b2e13f08c4013ab2459d9140f2523",
            "964af8310d6d4a809580ec7d33c3347d",
            "bc224db84ae84a5bb1cad01937d0b591",
            "2c2c50b3e5db4ad49bf086433a109089",
            "a36945c35cec46688d10f4a1906fdae9",
            "64343f9df4b3495c9f95f29797483533",
            "ff5432c8b03249caaea19161321928d4",
            "3c50ccdbf52b4d069ab7b78cfec346f4",
            "a2eb5171417e4cbbbe4c51a69877780e",
            "0643738d532548e98484c563f275c639",
            "3990eeeee2d545029d3428353e82f37e",
            "8b3aa27b27f346889b21a45f98ced112",
            "6c8c743b1bf74389902a950bbb3dcee0",
            "3c208f394eae4b75870aa00a7f5e5d52",
            "9f940b13ff004848aa4e9fd284ffba0a",
            "75ee3792d723450f9cf41f3506f6c2dc",
            "26b941a2bac848b48bdfc6c66f827314",
            "f4a61a33cf444c2f9a256c38c18a4c8d",
            "01be8b3cc72c4a939639c54406fe36e5",
            "25dcae3a7cfe47b9a08e68a660a561f4",
            "b4d78b9ac7814ab0aa401aae2d77a192",
            "ea2398f2e48a4ec5b4ecbfeb5ad33461",
            "fdef7ebfdb61466eb84d5a73575a2b9d",
            "6b0ffdb168f8492ea80c0e22d15cb2f9",
            "1af358a3d7cc428e948f26eec1840eb0",
            "20c344561f7c47f2bf0757df32eabc0a",
            "5f4e1b3bb97a48cf8665923a9788644f",
            "7a2d764737164642aec4bd5f5f74cfb5",
            "8b0ad380efa6450a8067943044b3657e",
            "5d1cc0b575c147daae9f9b0bf979e580",
            "8f272ce720d64f5db2ff5bc1a3294061"
          ]
        },
        "id": "9rhglLzy7r_j",
        "outputId": "21c328d1-d941-4dde-d9b3-c64595add243"
      },
      "source": [
        "\n",
        "# WandB – Initialize a new run\n",
        "wandb.init(project=\"transformers_tutorials_summarization_4\")\n",
        "\n",
        "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "# Defining some key variables that will be used later on in the training  \n",
        "config = wandb.config          # Initialize config\n",
        "config.TRAIN_BATCH_SIZE = 2    # input batch size for training (default: 64)\n",
        "config.VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n",
        "config.TRAIN_EPOCHS = 2        # number of epochs to train (default: 10)\n",
        "config.VAL_EPOCHS = 1 \n",
        "config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "config.SEED = 42               # random seed (default: 42)\n",
        "config.MAX_LEN = 512\n",
        "config.SUMMARY_LEN = 150 \n",
        "\n",
        "# Set random seeds and deterministic pytorch for reproducibility\n",
        "torch.manual_seed(config.SEED) # pytorch random seed\n",
        "np.random.seed(config.SEED) # numpy random seed\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# tokenzier for encoding the text\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "\n",
        "# Importing and Pre-Processing the domain data\n",
        "# Selecting the needed columns only. \n",
        "# Adding the summarzie text in front of the text. This is to format the dataset similar to how T5 model was trained for summarization task. \n",
        "#df = pd.read_csv('./data/news_summary.csv',encoding='latin-1')\n",
        "df = df_test\n",
        "df = df[['text','ctext']]\n",
        "df.ctext = 'summarize: ' + df.ctext\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Creation of Dataset and Dataloader\n",
        "# Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n",
        "train_size = 0.8\n",
        "train_dataset=df.sample(frac=train_size,random_state = config.SEED)\n",
        "val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
        "\n",
        "\n",
        "# Creating the Training and Validation dataset for further creation of Dataloader\n",
        "training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "\n",
        "# Defining the parameters for creation of dataloaders\n",
        "train_params = {\n",
        "    'batch_size': config.TRAIN_BATCH_SIZE,\n",
        "    'shuffle': True,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "val_params = {\n",
        "    'batch_size': config.VALID_BATCH_SIZE,\n",
        "    'shuffle': False,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "# Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "\n",
        "\n",
        "# Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "# Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "# Log metrics with wandb\n",
        "wandb.watch(model, log=\"all\")\n",
        "# Training loop\n",
        "print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "for epoch in range(config.TRAIN_EPOCHS):\n",
        "    train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "\n",
        "\n",
        "# Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "# Saving the dataframe as predictions.csv\n",
        "print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
        "for epoch in range(config.VAL_EPOCHS):\n",
        "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "    final_df.to_csv('./predictions2.csv')\n",
        "    print('Output Files generated for review')\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mselgh\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.28<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">likely-firefly-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/selgh/transformers_tutorials_summarization_4\" target=\"_blank\">https://wandb.ai/selgh/transformers_tutorials_summarization_4</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/selgh/transformers_tutorials_summarization_4/runs/1ppogbdq\" target=\"_blank\">https://wandb.ai/selgh/transformers_tutorials_summarization_4/runs/1ppogbdq</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210429_182102-1ppogbdq</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "969335932897426995eeb4e080f654cb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c50ccdbf52b4d069ab7b78cfec346f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1389353.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                                                     text                                              ctext\n",
            "83249   download and install 4videosoft video converte...  summarize: After the download is finished, run...\n",
            "106905  go to usps.com. sign in or register. click on ...  summarize: Visit https://www.usps.com/ from an...\n",
            "47589   confirm your system is capable of hosting a te...  summarize: You must have at least four GB avai...\n",
            "110851  buy fresh red snapper fillets. season the fill...  summarize: Pick out fillets with the skin on, ...\n",
            "30999   brush your hair. pull all of your hair back in...  summarize: Make sure to fully detangle your ha...\n",
            "FULL Dataset: (20000, 2)\n",
            "TRAIN Dataset: (16000, 2)\n",
            "TEST Dataset: (4000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75ee3792d723450f9cf41f3506f6c2dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b0ffdb168f8492ea80c0e22d15cb2f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initiating Fine-Tuning for the model on our dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  9.633550643920898\n",
            "Epoch: 0, Loss:  2.1604788303375244\n",
            "Epoch: 0, Loss:  2.5816893577575684\n",
            "Epoch: 0, Loss:  1.9990748167037964\n",
            "Epoch: 0, Loss:  2.7699592113494873\n",
            "Epoch: 0, Loss:  3.1951003074645996\n",
            "Epoch: 0, Loss:  3.307638645172119\n",
            "Epoch: 0, Loss:  2.739058017730713\n",
            "Epoch: 0, Loss:  2.3915586471557617\n",
            "Epoch: 0, Loss:  1.8106592893600464\n",
            "Epoch: 0, Loss:  2.737210988998413\n",
            "Epoch: 0, Loss:  2.723780870437622\n",
            "Epoch: 0, Loss:  2.048546552658081\n",
            "Epoch: 0, Loss:  2.5024538040161133\n",
            "Epoch: 0, Loss:  2.6963789463043213\n",
            "Epoch: 0, Loss:  2.7516796588897705\n",
            "Epoch: 1, Loss:  2.108342409133911\n",
            "Epoch: 1, Loss:  2.5467722415924072\n",
            "Epoch: 1, Loss:  1.5126205682754517\n",
            "Epoch: 1, Loss:  2.812560558319092\n",
            "Epoch: 1, Loss:  3.4646737575531006\n",
            "Epoch: 1, Loss:  2.7303357124328613\n",
            "Epoch: 1, Loss:  1.413732647895813\n",
            "Epoch: 1, Loss:  2.9658591747283936\n",
            "Epoch: 1, Loss:  2.2108750343322754\n",
            "Epoch: 1, Loss:  3.3777289390563965\n",
            "Epoch: 1, Loss:  1.9159938097000122\n",
            "Epoch: 1, Loss:  2.7035837173461914\n",
            "Epoch: 1, Loss:  2.68666410446167\n",
            "Epoch: 1, Loss:  2.4640774726867676\n",
            "Epoch: 1, Loss:  1.773515224456787\n",
            "Epoch: 1, Loss:  1.9608323574066162\n",
            "Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n",
            "Completed 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed 100\n",
            "Completed 200\n",
            "Completed 300\n",
            "Completed 400\n",
            "Completed 500\n",
            "Completed 600\n",
            "Completed 700\n",
            "Completed 800\n",
            "Completed 900\n",
            "Completed 1000\n",
            "Completed 1100\n",
            "Completed 1200\n",
            "Completed 1300\n",
            "Completed 1400\n",
            "Completed 1500\n",
            "Completed 1600\n",
            "Completed 1700\n",
            "Completed 1800\n",
            "Completed 1900\n",
            "Output Files generated for review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HasKIsJ-CKH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e27e1469-e860-4a45-eec1-f80258ee0251"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('./predictions2.csv') "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f87eb9ec-e801-41f2-86db-4e37b90c05dd\", \"predictions2.csv\", 1710328)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNU5laKpBbmM"
      },
      "source": [
        "model.save_pretrained('/content/')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rImheZI-a3gO"
      },
      "source": [
        "predictions = pd.read_csv('predictions2.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nG4z2oIf9e6"
      },
      "source": [
        "mean_rouge1 = 0\n",
        "mean_rougeL = 0\n",
        "mean_rouge2 = 0\n",
        "mean_meteor = 0\n",
        "n_articles = 4000\n",
        "\n",
        "for i in range(predictions.shape[0]) : \n",
        "      predicted_summary  = predictions.iloc[i]['Generated Text']\n",
        "      true_summary = predictions.iloc[i]['Actual Text']\n",
        "      scores = scorer.score(true_summary,\n",
        "                        predicted_summary)\n",
        "      score2 = metric.compute(predictions=[predicted_summary], references=[true_summary])\n",
        "\n",
        "      mean_rouge1 += scores['rouge1'].fmeasure\n",
        "      mean_rougeL += scores['rougeL'].fmeasure\n",
        "      mean_rouge2 += scores['rouge2'].fmeasure\n",
        "      mean_meteor += score2['meteor']\n",
        "\n",
        "mean_rouge1 = mean_rouge1/n_articles\n",
        "mean_rougeL = mean_rougeL/n_articles\n",
        "mean_rouge2 = mean_rouge2/n_articles\n",
        "mean_meteor = mean_meteor/n_articles"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKJ4fuvmgFW7",
        "outputId": "bab03cf2-d2ef-4f9f-8f55-60465ec4dad0"
      },
      "source": [
        "mean_rouge1,mean_rouge2,mean_rougeL,mean_meteor"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3320466870980815,\n",
              " 0.12735492004818227,\n",
              " 0.26146548413012716,\n",
              " 0.19176017287542643)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8ZmLe9UgPGK",
        "outputId": "fd5c7a59-ca40-439c-b8cb-534dcbf54657"
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JIvT_9-gWkB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}